{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import subprocess\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def count_variants(vcf_file):\n",
    "    \"\"\"Count the number of variants in a VCF file using subprocess.\"\"\"\n",
    "    if vcf_file.endswith('.gz'):\n",
    "        cmd = f\"bcftools view -H {vcf_file} | wc -l\"\n",
    "    else:\n",
    "        cmd = f\"grep -v '^#' {vcf_file} | wc -l\"\n",
    "    \n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    return int(result.stdout.strip())\n",
    "\n",
    "def filter_variants():\n",
    "    # Define input and output VCF files\n",
    "    INPUT_VCF = \"../data/freebayes.annotated_pc1.vcf.gz\"\n",
    "    QUAL_FILTERED_VCF = \"../data/filtered_qual.vcf\"\n",
    "    DP_FILTERED_VCF = \"../data/filtered_dp.vcf\"\n",
    "    SNP_FILTERED_VCF = \"../data/filtered_snp.vcf\"\n",
    "    FINAL_VCF = \"../data/filtered_final.vcf\"\n",
    "    \n",
    "    print(\"======================================\")\n",
    "    print(\"Starting Variant Filtering Process\")\n",
    "    print(\"======================================\")\n",
    "    \n",
    "    # Count initial number of variants\n",
    "    START_COUNT = count_variants(INPUT_VCF)\n",
    "    print(f\"Total variants before filtering: {START_COUNT}\")\n",
    "    \n",
    "    # Step 1: Filter out low-quality variants (QUAL < 30)\n",
    "    subprocess.run(f\"bcftools filter -e 'QUAL < 30' {INPUT_VCF} -o {QUAL_FILTERED_VCF}\", shell=True)\n",
    "    QUAL_FILTERED_COUNT = count_variants(QUAL_FILTERED_VCF)\n",
    "    print(f\"Stage 1: QUAL filtering: {START_COUNT - QUAL_FILTERED_COUNT} Variants removed and {QUAL_FILTERED_COUNT} variants left\")\n",
    "\n",
    "    # Step 2: Filter variants based on per-sample depth (FORMAT/DP < 10 or > 150)\n",
    "    subprocess.run(f\"bcftools view -i 'FMT/DP >= 30 & FMT/DP <= 150' {QUAL_FILTERED_VCF} -o {DP_FILTERED_VCF}\", shell=True)\n",
    "    DP_FILTERED_COUNT = count_variants(DP_FILTERED_VCF)\n",
    "    print(f\"Stage 2: FORMAT/DP filtering, DP >= 30 & DP <= 150: {QUAL_FILTERED_COUNT - DP_FILTERED_COUNT} Variants removed and {DP_FILTERED_COUNT} variants left\")\n",
    "\n",
    "    # Step 3: Retain SNPs and indels (Remove other variant types if any)\n",
    "    subprocess.run(f\"bcftools view -v snps,indels {DP_FILTERED_VCF} -o {SNP_FILTERED_VCF}\", shell=True)\n",
    "    SNP_FILTERED_COUNT = count_variants(SNP_FILTERED_VCF)\n",
    "    print(f\"Stage 3: After keeping SNPs and indels: {DP_FILTERED_COUNT - SNP_FILTERED_COUNT} Variants removed and {SNP_FILTERED_COUNT} variants left\")\n",
    "\n",
    "    # Rename final output\n",
    "    os.rename(SNP_FILTERED_VCF, FINAL_VCF)\n",
    "    FINAL_COUNT = count_variants(FINAL_VCF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def read_vcf(vcf_file):\n",
    "    \"\"\"Reads a VCF file, automatically detecting the header and using correct column names.\"\"\"\n",
    "    \n",
    "    # Find the header line dynamically\n",
    "    with open(vcf_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#CHROM\"):\n",
    "                header = line.strip().split(\"\\t\")  # Extract column names\n",
    "                break  # Stop searching after finding header\n",
    "    \n",
    "    # Read VCF using Pandas, skipping comment lines\n",
    "    df = pd.read_csv(vcf_file, sep=\"\\t\", comment=\"#\", header=None, names=header)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def find_index(format_value, field):\n",
    "    \"\"\"Finds the index of a specific field (e.g., RO, AO, DP) in the FORMAT column.\"\"\"\n",
    "    item_list = format_value.split(':')\n",
    "    return item_list.index(field) if field in item_list else None\n",
    "\n",
    "def expand_multiallelic_variants(df_vcf):\n",
    "    \"\"\"\n",
    "    Extracts allele counts (RO, AO, DP) for each sample from the VCF DataFrame\n",
    "    and expands multi-allelic variants into separate rows.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract sample names (everything after FORMAT column)\n",
    "    sample_names = df_vcf.columns[9:]  # Skip CHROM, POS, ID, REF, ALT, QUAL, FILTER, INFO, FORMAT\n",
    "\n",
    "    # Find the index positions of RO, AO, and DP in the FORMAT field\n",
    "    format_example = df_vcf['FORMAT'].values[0]  # Take the first row as an example\n",
    "    ro_index = find_index(format_example, 'RO')\n",
    "    ao_index = find_index(format_example, 'AO')\n",
    "    dp_index = find_index(format_example, 'DP')\n",
    "\n",
    "    # Ensure indices exist\n",
    "    if None in [ro_index, ao_index, dp_index]:\n",
    "        raise ValueError(\"RO, AO, or DP field not found in FORMAT column.\")\n",
    "\n",
    "    # Initialize an empty list to store expanded rows\n",
    "    expanded_rows = []\n",
    "\n",
    "    for _, row in df_vcf.iterrows():\n",
    "        # Split ALT alleles (multi-allelic sites will have multiple ALT values)\n",
    "        alt_alleles = row['ALT'].split(',')\n",
    "\n",
    "        # Process each ALT allele separately\n",
    "        for i, alt in enumerate(alt_alleles):\n",
    "            new_row = {\n",
    "                \"#CHROM\": row[\"#CHROM\"],\n",
    "                \"POS\": row[\"POS\"],\n",
    "                \"REF\": row[\"REF\"],\n",
    "                \"ALT\": alt  # Assign each alternate allele to a separate row\n",
    "            }\n",
    "\n",
    "            for sample in sample_names:\n",
    "                # Split FORMAT fields for the sample\n",
    "                sample_values = row[sample].split(':')\n",
    "                \n",
    "                # Extract and store RO and DP\n",
    "                new_row[f\"RO_{sample}\"] = int(sample_values[ro_index]) if sample_values[ro_index] != '.' else 0\n",
    "                new_row[f\"DP_{sample}\"] = int(sample_values[dp_index]) if sample_values[dp_index] != '.' else 0\n",
    "\n",
    "                # Extract AO for the specific ALT allele\n",
    "                ao_values = sample_values[ao_index].split(',')  # Multiple values for multiple ALT alleles\n",
    "                new_row[f\"AO_{sample}\"] = int(ao_values[i]) if i < len(ao_values) and ao_values[i] != '.' else 0\n",
    "\n",
    "            # Append expanded row\n",
    "            expanded_rows.append(new_row)\n",
    "\n",
    "    # Convert list of dictionaries into DataFrame\n",
    "    expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "    return expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
