{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import subprocess\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from pycirclize import Circos\n",
    "from pycirclize.parser import Gff\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def count_variants(vcf_file):\n",
    "    \"\"\"Count the number of variants in a VCF file using subprocess.\"\"\"\n",
    "    if vcf_file.endswith('.gz'):\n",
    "        cmd = f\"bcftools view -H {vcf_file} | wc -l\"\n",
    "    else:\n",
    "        cmd = f\"grep -v '^#' {vcf_file} | wc -l\"\n",
    "    \n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    return int(result.stdout.strip())\n",
    "\n",
    "def filter_variants():\n",
    "    # Define input and output VCF files\n",
    "    INPUT_VCF = \"../data/freebayes.annotated_pc1.vcf.gz\"\n",
    "    QUAL_FILTERED_VCF = \"../data/filtered_qual.vcf\"\n",
    "    DP_FILTERED_VCF = \"../data/filtered_dp.vcf\"\n",
    "    SNP_FILTERED_VCF = \"../data/filtered_snp.vcf\"\n",
    "    FINAL_VCF = \"../data/filtered_final.vcf\"\n",
    "    \n",
    "    print(\"======================================\")\n",
    "    print(\"Starting Variant Filtering Process\")\n",
    "    print(\"======================================\")\n",
    "    \n",
    "    # Count initial number of variants\n",
    "    START_COUNT = count_variants(INPUT_VCF)\n",
    "    print(f\"Total variants before filtering: {START_COUNT}\")\n",
    "    \n",
    "    # Step 1: Filter out low-quality variants (QUAL < 30)\n",
    "    subprocess.run(f\"bcftools filter -e 'QUAL < 30' {INPUT_VCF} -o {QUAL_FILTERED_VCF}\", shell=True)\n",
    "    QUAL_FILTERED_COUNT = count_variants(QUAL_FILTERED_VCF)\n",
    "    print(f\"Stage 1: QUAL filtering: {START_COUNT - QUAL_FILTERED_COUNT} Variants removed and {QUAL_FILTERED_COUNT} variants left\")\n",
    "\n",
    "    # Step 2: Filter variants based on per-sample depth (FORMAT/DP < 10 or > 150)\n",
    "    subprocess.run(f\"bcftools view -i 'FMT/DP >= 30 & FMT/DP <= 150' {QUAL_FILTERED_VCF} -o {DP_FILTERED_VCF}\", shell=True)\n",
    "    DP_FILTERED_COUNT = count_variants(DP_FILTERED_VCF)\n",
    "    print(f\"Stage 2: FORMAT/DP filtering, DP >= 30 & DP <= 150: {QUAL_FILTERED_COUNT - DP_FILTERED_COUNT} Variants removed and {DP_FILTERED_COUNT} variants left\")\n",
    "\n",
    "    # Step 3: Retain SNPs and indels (Remove other variant types if any)\n",
    "    subprocess.run(f\"bcftools view -v snps,indels {DP_FILTERED_VCF} -o {SNP_FILTERED_VCF}\", shell=True)\n",
    "    SNP_FILTERED_COUNT = count_variants(SNP_FILTERED_VCF)\n",
    "    print(f\"Stage 3: After keeping SNPs and indels: {DP_FILTERED_COUNT - SNP_FILTERED_COUNT} Variants removed and {SNP_FILTERED_COUNT} variants left\")\n",
    "\n",
    "    # Rename final output\n",
    "    os.rename(SNP_FILTERED_VCF, FINAL_VCF)\n",
    "    FINAL_COUNT = count_variants(FINAL_VCF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def read_vcf(vcf_file):\n",
    "    \"\"\"Reads a VCF file, automatically detecting the header and using correct column names.\"\"\"\n",
    "    \n",
    "    # Find the header line dynamically\n",
    "    with open(vcf_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#CHROM\"):\n",
    "                header = line.strip().split(\"\\t\")  # Extract column names\n",
    "                break  # Stop searching after finding header\n",
    "    \n",
    "    # Read VCF using Pandas, skipping comment lines\n",
    "    df = pd.read_csv(vcf_file, sep=\"\\t\", comment=\"#\", header=None, names=header)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def find_index(format_value, field):\n",
    "    \"\"\"Finds the index of a specific field (e.g., RO, AO, DP) in the FORMAT column.\"\"\"\n",
    "    item_list = format_value.split(':')\n",
    "    return item_list.index(field) if field in item_list else None\n",
    "\n",
    "def expand_multiallelic_variants(df_vcf):\n",
    "    \"\"\"\n",
    "    Extracts allele counts (RO, AO, DP) for each sample from the VCF DataFrame\n",
    "    and expands multi-allelic variants into separate rows.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract sample names (everything after FORMAT column)\n",
    "    sample_names = df_vcf.columns[9:]  # Skip CHROM, POS, ID, REF, ALT, QUAL, FILTER, INFO, FORMAT\n",
    "\n",
    "    # Find the index positions of RO, AO, and DP in the FORMAT field\n",
    "    format_example = df_vcf['FORMAT'].values[0]  # Take the first row as an example\n",
    "    ro_index = find_index(format_example, 'RO')\n",
    "    ao_index = find_index(format_example, 'AO')\n",
    "    dp_index = find_index(format_example, 'DP')\n",
    "\n",
    "    # Ensure indices exist\n",
    "    if None in [ro_index, ao_index, dp_index]:\n",
    "        raise ValueError(\"RO, AO, or DP field not found in FORMAT column.\")\n",
    "\n",
    "    # Initialize an empty list to store expanded rows\n",
    "    expanded_rows = []\n",
    "\n",
    "    for _, row in df_vcf.iterrows():\n",
    "        # Split ALT alleles (multi-allelic sites will have multiple ALT values)\n",
    "        alt_alleles = row['ALT'].split(',')\n",
    "\n",
    "        # Process each ALT allele separately\n",
    "        for i, alt in enumerate(alt_alleles):\n",
    "            new_row = {\n",
    "                \"#CHROM\": row[\"#CHROM\"],\n",
    "                \"POS\": row[\"POS\"],\n",
    "                \"REF\": row[\"REF\"],\n",
    "                \"ALT\": alt  # Assign each alternate allele to a separate row\n",
    "            }\n",
    "\n",
    "            for sample in sample_names:\n",
    "                # Split FORMAT fields for the sample\n",
    "                sample_values = row[sample].split(':')\n",
    "                \n",
    "                # Extract and store RO and DP\n",
    "                new_row[f\"RO_{sample}\"] = int(sample_values[ro_index]) if sample_values[ro_index] != '.' else 0\n",
    "                new_row[f\"DP_{sample}\"] = int(sample_values[dp_index]) if sample_values[dp_index] != '.' else 0\n",
    "\n",
    "                # Extract AO for the specific ALT allele\n",
    "                ao_values = sample_values[ao_index].split(',')  # Multiple values for multiple ALT alleles\n",
    "                new_row[f\"AO_{sample}\"] = int(ao_values[i]) if i < len(ao_values) and ao_values[i] != '.' else 0\n",
    "\n",
    "            # Append expanded row\n",
    "            expanded_rows.append(new_row)\n",
    "\n",
    "    # Convert list of dictionaries into DataFrame\n",
    "    expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "    return expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def compute_frequencies(df_counts):\n",
    "    \"\"\"\n",
    "    Computes allele frequency (AF = AO / DP) for each sample in the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract sample names from AO columns\n",
    "    sample_names = [col.replace(\"AO_\", \"\") for col in df_counts.columns if col.startswith(\"AO_\")]\n",
    "\n",
    "    # Create a new DataFrame to store allele frequencies\n",
    "    df_af = df_counts[['#CHROM', 'POS', 'REF', 'ALT']].copy()\n",
    "\n",
    "    for sample in sample_names:\n",
    "        ao_col = f\"AO_{sample}\"\n",
    "        dp_col = f\"DP_{sample}\"\n",
    "        af_col = f\"AF_{sample}\"\n",
    "        df_af[af_col] = df_counts[ao_col] / df_counts[dp_col] #(df_counts[ro_col] + df_counts[ao_col])\n",
    "\n",
    "    return df_af\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def mod_hist_legend(ax, title=False):\n",
    "    \"\"\"\n",
    "    Creates a cleaner legend for histogram plots by using line elements instead of patches.\n",
    "    \n",
    "    Motivation:\n",
    "    - Default histogram legends show rectangle patches which can be visually distracting\n",
    "    - This function creates a more elegant legend with simple lines matching histogram edge colors\n",
    "    - Positions the legend outside the plot to avoid overlapping with data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axes object containing the histogram(s)\n",
    "    title : str or bool, default=False\n",
    "        Optional title for the legend. If False, no title is displayed\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    None - modifies the axes object in place\n",
    "    \"\"\"\n",
    "    # Extract the current handles and labels from the plot\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    \n",
    "    # Create new line handles that match the edge colors of histogram bars\n",
    "    # This produces a cleaner, more minimal legend appearance\n",
    "    new_handles = [matplotlib.lines.Line2D([], [], c=h.get_edgecolor()) for h in handles]\n",
    "    \n",
    "    # Create the legend with custom positioning\n",
    "    # - Places legend outside the plot (to the right) to avoid obscuring the data\n",
    "    # - Centers the legend vertically for better visual balance\n",
    "    ax.legend(handles=new_handles, \n",
    "              labels=labels, \n",
    "              title=title,\n",
    "              loc='center left', \n",
    "              bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "\n",
    "def clean_axes(ax, offset=10):\n",
    "    \"\"\"\n",
    "    Customizes a matplotlib axes by removing top and right spines,\n",
    "    and creating a broken axis effect where x and y axes don't touch.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axes object to customize\n",
    "    offset : int, default=10\n",
    "        The amount of offset/gap between the x and y axes in points\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The same axes object, modified in place\n",
    "    \"\"\"\n",
    "    # Remove the top and right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    # Make the remaining spines gray for a more subtle look\n",
    "    ax.spines['left'].set_color('gray')\n",
    "    ax.spines['bottom'].set_color('gray')\n",
    "    \n",
    "    # Create the broken axis effect\n",
    "    # Move the bottom spine up by offset points\n",
    "    #ax.spines['bottom'].set_position(('outward', offset))\n",
    "    \n",
    "    # Move the left spine right by offset points\n",
    "    ax.spines['left'].set_position(('outward', offset))\n",
    "    \n",
    "    # Return the modified axes\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def make_circos_plot(data):\n",
    "    \n",
    "    seqid2size = {\n",
    "        'CM000429': 875659,\n",
    "        'CM000430': 985969,\n",
    "        'CM000431': 1099352,\n",
    "        'CM000432': 1104417,\n",
    "        'CM000433': 1080900,\n",
    "        'CM000434': 1332857,\n",
    "        'CM000435': 1278458,\n",
    "        'CM000436': 1344712\n",
    "    }\n",
    "\n",
    "    color_dict = {'M': 'blue', 'C': 'magenta'}\n",
    "\n",
    "    circos = Circos(seqid2size, space=3, start=-83, end=265, endspace=False)\n",
    "    circos.text(\"C. parvum IowaII\", r=5, size=18, font={'style': 'italic'})\n",
    "    \n",
    "    m_samples = ['AF_M7', 'AF_M5', 'AF_M6', 'AF_M4']\n",
    "    c_samples = ['AF_C3', 'AF_C2', 'AF_C1']\n",
    "    \n",
    "    for sector in circos.sectors:\n",
    "        sector.text(sector.name[-3:])\n",
    "        \n",
    "        m_track = sector.add_track((80, 100))\n",
    "        m_track.xticks_by_interval(200000, show_label=False)\n",
    "        m_track.axis()\n",
    "    \n",
    "        \n",
    "        c_track = sector.add_track((55, 75))\n",
    "        c_track.xticks_by_interval(200000, show_label=False)\n",
    "        c_track.axis()\n",
    "        \n",
    "        # Plot scatter points for each sample group\n",
    "        for sample in m_samples:\n",
    "            color = color_dict[sample[3]]\n",
    "            subset = data[(data['#CHROM'] == sector.name) & (data[sample] > 0)]\n",
    "            m_track.scatter(\n",
    "                x=subset['POS'].values,\n",
    "                y=subset[sample].values,\n",
    "                c=color,\n",
    "                s=3,\n",
    "                vmin=0,\n",
    "                vmax=1,\n",
    "                alpha=0.3,\n",
    "            )\n",
    "        \n",
    "        \n",
    "        for sample in c_samples:\n",
    "            color = color_dict[sample[3]]\n",
    "            subset = data[(data['#CHROM'] == sector.name) & (data[sample] > 0)]\n",
    "            c_track.scatter(\n",
    "                x=subset['POS'].values,\n",
    "                y=subset[sample].values,\n",
    "                c=color,\n",
    "                s=3,\n",
    "                vmin=0,\n",
    "                vmax=1,\n",
    "                alpha=0.3,\n",
    "            )\n",
    "\n",
    "        \n",
    "        # Optional: Add labels \n",
    "        if sector.name == 'CM000429':\n",
    "            m_track.yticks([0, 1], [\"0\", \"1\"], side=\"left\")\n",
    "            c_track.yticks([0, 1], [\"0\", \"1\"], side=\"left\")\n",
    "\n",
    "            \n",
    "            circos.text(\"Cow\", r=c_track.r_center, deg=-90, color=\"magenta\")\n",
    "            circos.text(\"Mouse\", r=m_track.r_center, deg=-90, color=\"blue\")\n",
    "    \n",
    "    circos.plotfig()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
